{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":262177,"sourceType":"datasetVersion","datasetId":107946},{"sourceId":2497231,"sourceType":"datasetVersion","datasetId":1512017}],"dockerImageVersionId":30824,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score\nimport numpy as np\nfrom PIL import Image\nimport os\nfrom torch.optim import Adam\nimport copy\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nclass SignatureDataset(Dataset):\n    def __init__(self, root_dir, subset='train', transform=None):\n        self.root_dir = os.path.join(root_dir, subset)\n        self.transform = transform\n        \n        # Verify root directory exists\n        if not os.path.exists(self.root_dir):\n            raise ValueError(f\"Directory not found: {self.root_dir}\")\n            \n        print(f\"\\nAnalyzing directory: {self.root_dir}\")\n        self.pairs = self._create_pairs()\n        print(f\"Total pairs created: {len(self.pairs)}\")\n        \n        if len(self.pairs) == 0:\n            print(f\"\\nDirectory structure for {self.root_dir}:\")\n            self._print_directory_structure(self.root_dir)\n            raise ValueError(f\"No valid pairs found in {self.root_dir}\")\n    \n    def _print_directory_structure(self, startpath):\n        for root, dirs, files in os.walk(startpath):\n            level = root.replace(startpath, '').count(os.sep)\n            indent = ' ' * 4 * level\n            print(f'{indent}{os.path.basename(root)}/')\n            subindent = ' ' * 4 * (level + 1)\n            for f in files:\n                if f.endswith(('.png', '.jpg', '.jpeg')):\n                    print(f'{subindent}{f}')\n    \n    def _create_pairs(self):\n        pairs = []\n        genuine_folders = []\n        \n        # Get all subdirectories\n        for item in os.listdir(self.root_dir):\n            if os.path.isdir(os.path.join(self.root_dir, item)):\n                if not item.endswith('_forg'):\n                    genuine_folders.append(item)\n        \n        print(f\"Found genuine folders: {genuine_folders}\")\n        \n        for folder in genuine_folders:\n            genuine_path = os.path.join(self.root_dir, folder)\n            forged_path = os.path.join(self.root_dir, f\"{folder}_forg\")\n            \n            if not os.path.exists(forged_path):\n                print(f\"Warning: No forged folder found for {folder}\")\n                continue\n            \n            # Get genuine and forged images\n            genuine_images = [f for f in os.listdir(genuine_path) \n                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n            forged_images = [f for f in os.listdir(forged_path) \n                           if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n            \n            print(f\"\\nFolder {folder}:\")\n            print(f\"  Genuine images: {len(genuine_images)}\")\n            print(f\"  Forged images: {len(forged_images)}\")\n            \n            # Create genuine pairs\n            for i in range(len(genuine_images)):\n                for j in range(i + 1, len(genuine_images)):\n                    pairs.append((\n                        os.path.join(genuine_path, genuine_images[i]),\n                        os.path.join(genuine_path, genuine_images[j]),\n                        1  # genuine pair\n                    ))\n            \n            # Create forged pairs\n            for genuine_img in genuine_images:\n                for forged_img in forged_images:\n                    pairs.append((\n                        os.path.join(genuine_path, genuine_img),\n                        os.path.join(forged_path, forged_img),\n                        0  # forged pair\n                    ))\n        \n        return pairs\n    \n    def __len__(self):\n        return len(self.pairs)\n    \n    def __getitem__(self, idx):\n        img1_path, img2_path, label = self.pairs[idx]\n        \n        try:\n            img1 = Image.open(img1_path).convert('RGB')\n            img2 = Image.open(img2_path).convert('RGB')\n        except Exception as e:\n            print(f\"Error loading images:\\nPath 1: {img1_path}\\nPath 2: {img2_path}\\nError: {str(e)}\")\n            raise\n        \n        if self.transform:\n            img1 = self.transform(img1)\n            img2 = self.transform(img2)\n        \n        return img1, img2, torch.FloatTensor([label])\n\nclass SiameseNetwork(nn.Module):\n    def __init__(self):\n        super(SiameseNetwork, self).__init__()\n        self.cnn = models.resnet18(pretrained=True)\n        self.cnn.fc = nn.Linear(self.cnn.fc.in_features, 256)\n        \n        self.fc1 = nn.Sequential(\n            nn.Linear(256 * 2, 512),\n            nn.ReLU(inplace=True),\n            nn.Linear(512, 1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, img1, img2):\n        feat1 = self.cnn(img1)\n        feat2 = self.cnn(img2)\n        combined = torch.cat((feat1, feat2), 1)\n        output = self.fc1(combined)\n        return output\n\ndef train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, patience):\n    best_accuracy = 0.0\n    best_model_wts = copy.deepcopy(model.state_dict())\n    train_losses = []\n    test_losses = []\n    patience_counter = 0\n\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n\n        for img1, img2, labels in train_loader:\n            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(img1, img2)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * img1.size(0)\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        train_losses.append(epoch_loss)\n\n        # Validate\n        model.eval()\n        test_loss = 0.0\n        corrects = 0\n        all_labels = []\n        all_preds = []\n\n        with torch.no_grad():\n            for img1, img2, labels in test_loader:\n                img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n                outputs = model(img1, img2)\n                loss = criterion(outputs, labels)\n                test_loss += loss.item() * img1.size(0)\n                preds = (outputs > 0.5).float()\n                corrects += (preds == labels).sum().item()\n                all_labels.extend(labels.cpu().numpy())\n                all_preds.extend(preds.cpu().numpy())\n\n        epoch_test_loss = test_loss / len(test_loader.dataset)\n        test_losses.append(epoch_test_loss)\n        accuracy = corrects / len(test_loader.dataset)\n        print(f'Epoch {epoch}/{num_epochs - 1}, '\n              f'Train Loss: {epoch_loss:.4f}, '\n              f'Test Loss: {epoch_test_loss:.4f}, '\n              f'Accuracy: {accuracy:.4f}')\n\n        # Check if this is the best model so far\n        if accuracy > best_accuracy:\n            best_accuracy = accuracy\n            best_model_wts = copy.deepcopy(model.state_dict())\n            torch.save(model.state_dict(), '/kaggle/working/best_model.pth')\n            patience_counter = 0\n        else:\n            patience_counter += 1\n\n        # Early stopping\n        if patience_counter >= patience:\n            print(\"Early stopping\")\n            break\n\n        # Calculate confusion matrix for this epoch\n        cm = confusion_matrix(all_labels, all_preds)\n        print(f'Confusion Matrix (Epoch {epoch}):\\n{cm}')\n\n    # Load the best model weights\n    model.load_state_dict(best_model_wts)\n\n    return train_losses, test_losses, best_accuracy, cm\n\ndef main():\n    # Data transforms\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    # Dataset paths for Kaggle\n    dataset_root = '/kaggle/input/signature-verification-dataset/sign_data'\n    \n    print(\"\\nInitializing training dataset...\")\n    train_dataset = SignatureDataset(dataset_root, subset='train', transform=transform)\n    \n    print(\"\\nInitializing testing dataset...\")\n    test_dataset = SignatureDataset(dataset_root, subset='test', transform=transform)\n    \n    # Create data loaders with num_workers=0 for debugging\n    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n    \n    # Initialize model\n    model = SiameseNetwork().to(device)\n    criterion = nn.BCELoss()\n    optimizer = Adam(model.parameters(), lr=0.0001)\n    \n    # Training parameters\n    num_epochs = 50\n    patience = 7\n    \n    # Train model\n    train_losses, test_losses, best_accuracy, cm = train_model(\n        model, train_loader, test_loader, criterion, optimizer, num_epochs, patience\n    )\n    \n    # Save final results\n    print(f\"\\nBest accuracy achieved: {best_accuracy:.2f}%\")\n    \n    # Save the final model\n    torch.save(model.state_dict(), '/kaggle/working/final_model.pth')\n    \n    # Save the visualization plots to Kaggle working directory\n    plt.figure(figsize=(10, 5))\n    plt.plot(train_losses, label='Training Loss')\n    plt.plot(test_losses, label='Test Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training and Test Loss')\n    plt.legend()\n    plt.savefig('/kaggle/working/training_test_loss_plot.png')\n    plt.show()\n\n    # Plot confusion matrix\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Forged', 'Genuine'], yticklabels=['Forged', 'Genuine'])\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title('Confusion Matrix')\n    plt.savefig('/kaggle/working/confusion_matrix.png')\n    plt.show()\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T01:33:52.441274Z","iopub.execute_input":"2024-12-22T01:33:52.441475Z"}},"outputs":[{"name":"stdout","text":"\nInitializing training dataset...\n\nAnalyzing directory: /kaggle/input/signature-verification-dataset/sign_data/train\nFound genuine folders: ['057', '061', '048', '053', '051', '018', '044', '016', '009', '012', '029', '025', '001', '056', '006', '042', '055', '027', '041', '036', '035', '026', '065', '062', '034', '058', '060', '068', '033', '049', '023', '020', '013', '050', '052', '066', '002', '067', '022', '043', '054', '047', '004', '021', '015', '059', '014', '039', '040', '064', '063', '031', '017', '003', '019', '024', '069', '037', '046', '045', '028', '038', '032', '030']\n\nFolder 057:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 061:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 048:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 053:\n  Genuine images: 12\n  Forged images: 16\n\nFolder 051:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 018:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 044:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 016:\n  Genuine images: 23\n  Forged images: 16\n\nFolder 009:\n  Genuine images: 24\n  Forged images: 12\n\nFolder 012:\n  Genuine images: 24\n  Forged images: 12\n\nFolder 029:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 025:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 001:\n  Genuine images: 24\n  Forged images: 8\n\nFolder 056:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 006:\n  Genuine images: 24\n  Forged images: 12\n\nFolder 042:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 055:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 027:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 041:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 036:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 035:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 026:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 065:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 062:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 034:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 058:\n  Genuine images: 12\n  Forged images: 16\n\nFolder 060:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 068:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 033:\n  Genuine images: 12\n  Forged images: 16\n\nFolder 049:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 023:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 020:\n  Genuine images: 12\n  Forged images: 19\n\nFolder 013:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 050:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 052:\n  Genuine images: 12\n  Forged images: 16\n\nFolder 066:\n  Genuine images: 12\n  Forged images: 16\n\nFolder 002:\n  Genuine images: 24\n  Forged images: 12\n\nFolder 067:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 022:\n  Genuine images: 12\n  Forged images: 16\n\nFolder 043:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 054:\n  Genuine images: 12\n  Forged images: 20\n\nFolder 047:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 004:\n  Genuine images: 24\n  Forged images: 11\n\nFolder 021:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 015:\n  Genuine images: 24\n  Forged images: 12\n\nFolder 059:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 014:\n  Genuine images: 24\n  Forged images: 16\n\nFolder 039:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 040:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 064:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 063:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 031:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 017:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 003:\n  Genuine images: 24\n  Forged images: 12\n\nFolder 019:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 024:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 069:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 037:\n  Genuine images: 12\n  Forged images: 16\n\nFolder 046:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 045:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 028:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 038:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 032:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 030:\n  Genuine images: 12\n  Forged images: 12\nTotal pairs created: 16905\n\nInitializing testing dataset...\n\nAnalyzing directory: /kaggle/input/signature-verification-dataset/sign_data/test\nFound genuine folders: ['057', '061', '053', '051', '056', '055', '065', '062', '058', '060', '068', '049', '050', '052', '066', '067', '054', '059', '064', '063', '069']\n\nFolder 057:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 061:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 053:\n  Genuine images: 12\n  Forged images: 16\n\nFolder 051:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 056:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 055:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 065:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 062:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 058:\n  Genuine images: 12\n  Forged images: 16\n\nFolder 060:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 068:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 049:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 050:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 052:\n  Genuine images: 12\n  Forged images: 16\n\nFolder 066:\n  Genuine images: 12\n  Forged images: 16\n\nFolder 067:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 054:\n  Genuine images: 12\n  Forged images: 20\n\nFolder 059:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 064:\n  Genuine images: 12\n  Forged images: 8\n\nFolder 063:\n  Genuine images: 12\n  Forged images: 12\n\nFolder 069:\n  Genuine images: 12\n  Forged images: 12\nTotal pairs created: 4362\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 203MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0/49, Train Loss: 0.0290, Test Loss: 0.0417, Accuracy: 0.9812\nConfusion Matrix (Epoch 0):\n[[2976    0]\n [  82 1304]]\nEpoch 1/49, Train Loss: 0.0034, Test Loss: 0.0467, Accuracy: 0.9876\nConfusion Matrix (Epoch 1):\n[[2976    0]\n [  54 1332]]\nEpoch 2/49, Train Loss: 0.0001, Test Loss: 0.0158, Accuracy: 0.9966\nConfusion Matrix (Epoch 2):\n[[2976    0]\n [  15 1371]]\nEpoch 3/49, Train Loss: 0.0044, Test Loss: 0.2082, Accuracy: 0.9541\nConfusion Matrix (Epoch 3):\n[[2976    0]\n [ 200 1186]]\n","output_type":"stream"}],"execution_count":null}]}